import os
import cv2
import json
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms
import time

# ---------------------- 1. åŸºç¡€å·¥å…·æ¨¡å—ï¼ˆDeepSeekï¼šæ¨¡å—åŒ–è®¾è®¡ï¼Œé™ä½è€¦åˆï¼‰ ----------------------
def validate_file_path(file_path: str) -> None:
    """éªŒè¯æ–‡ä»¶è·¯å¾„æœ‰æ•ˆæ€§ï¼ˆè§„é¿å†å²è¯»å–é”™è¯¯ï¼‰"""
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼š{file_path}\nè¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦åŒ…å«ä¸­æ–‡/ç©ºæ ¼ï¼Œæˆ–æ–‡ä»¶æ˜¯å¦è¢«åˆ é™¤")
    if not file_path.lower().endswith(('.png', '.jpg', '.jpeg')):
        raise ValueError(f"æ–‡ä»¶æ ¼å¼ä¸æ”¯æŒï¼š{file_path}\nä»…æ”¯æŒPNG/JPG/JPEGå›¾åƒ")

def load_image_safely(file_path: str) -> np.ndarray:
    """å®‰å…¨åŠ è½½å›¾åƒï¼ˆå¤šæ¨¡å¼è¯»å–+PILå…¼å®¹ï¼Œè§£å†³OpenCVè¯»å–å¤±è´¥é—®é¢˜ï¼‰"""
    validate_file_path(file_path)
    # ä¼˜å…ˆç”¨PILè¯»å–ï¼ˆå…¼å®¹æ€§ä¼˜äºOpenCVï¼Œè§£å†³ç‰¹æ®Šç¼–ç /é€æ˜é€šé“å›¾åƒé—®é¢˜ï¼‰
    try:
        from PIL import Image
        # è¯»å–å¹¶è½¬ä¸ºç°åº¦å›¾ï¼ˆç»Ÿä¸€æ¨¡å‹è¾“å…¥æ ¼å¼ï¼‰
        img_pil = Image.open(file_path).convert('L')  # 'L'æ¨¡å¼å¯¹åº”ç°åº¦å›¾
        img = np.array(img_pil)
        return img
    except ImportError:
        # è‹¥æœªå®‰è£…PILï¼Œç”¨OpenCVå¤šæ¨¡å¼å…œåº•
        read_modes = [cv2.IMREAD_GRAYSCALE, cv2.IMREAD_COLOR, cv2.IMREAD_UNCHANGED]
        for mode in read_modes:
            img = cv2.imread(file_path, mode)
            if img is not None:
                # å½©è‰²å›¾è½¬ç°åº¦å›¾ï¼Œé™ä½ç»´åº¦
                if len(img.shape) == 3:
                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                return img
    except Exception as pil_err:
        # PILè¯»å–å¤±è´¥ï¼Œè¡¥å……OpenCVå…œåº•
        read_modes = [cv2.IMREAD_GRAYSCALE, cv2.IMREAD_COLOR, cv2.IMREAD_UNCHANGED]
        for mode in read_modes:
            img = cv2.imread(file_path, mode)
            if img is not None:
                if len(img.shape) == 3:
                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                return img
    # æ‰€æœ‰æ–¹å¼å¤±è´¥ï¼ŒæŠ›å‡ºè¯¦ç»†é”™è¯¯
    raise Exception(
        f"å›¾åƒåŠ è½½å¤±è´¥ï¼š{file_path}\n"
        f"å¯èƒ½åŸå› ï¼š1.æ–‡ä»¶æŸå 2.ç‰¹æ®Šç¼–ç æ ¼å¼ 3.æƒé™ä¸è¶³ 4.æœªå®‰è£…PILåº“ï¼ˆå»ºè®®æ‰§è¡Œpip install pillowï¼‰"
    )

# ---------------------- 2. DeepSeeké£æ ¼è½»é‡çº§åˆ†ç±»æ¨¡å‹ï¼ˆå‚è€ƒæ–‡æ¡£ï¼šè½»é‡åŒ–+é«˜ç²¾åº¦å¹³è¡¡ï¼‰ ----------------------
class DeepSeekLightModel(nn.Module):
    """è½»é‡çº§å›¾åƒåˆ†ç±»æ¨¡å‹ï¼ˆå€Ÿé‰´DeepSeekæ•ˆç‡ä¼˜åŒ–æ€è·¯ï¼Œå‚è€ƒMobilenetv3_smallæ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼‰"""
    def __init__(self, num_classes: int = 2):
        super().__init__()
        # ç‰¹å¾æå–å±‚ï¼šæ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼ˆå‡å°‘å‚æ•°é‡ï¼Œé€‚é…CPUæ¨ç†ï¼‰
        self.features = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, padding=1),  # è¾“å…¥ï¼š1é€šé“ï¼ˆç°åº¦å›¾ï¼‰
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, kernel_size=3, padding=1, groups=32),  # æ·±åº¦å¯åˆ†ç¦»å·ç§¯
            nn.Conv2d(64, 64, kernel_size=1),  # ç‚¹å·ç§¯è°ƒæ•´é€šé“æ•°
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )
        # åˆ†ç±»å±‚ï¼šè‡ªé€‚åº”æ± åŒ–+å…¨è¿æ¥ï¼ˆç®€åŒ–ç»“æ„ï¼Œæå‡æ¨ç†é€Ÿåº¦ï¼‰
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(64, num_classes)
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.features(x)
        x = self.classifier(x)
        return x

# ---------------------- 3. æ ¸å¿ƒè¯†åˆ«ä¸JSONç”Ÿæˆæµç¨‹ï¼ˆDeepSeekï¼šç»“æ„åŒ–è¾“å‡ºï¼Œæ¸…æ™°å¯è¿½æº¯ï¼‰ ----------------------
def deepseek_image_recognition(
    img_path: str = r"C:\Users\thy\Desktop\å›¾åƒ1.png",  # ç›®æ ‡å›¾åƒè·¯å¾„ï¼ˆå·²æ›´æ–°ï¼‰
    output_json: str = r"C:\Users\thy\Desktop\å›¾åƒ1è¯†åˆ«ç»“æœ.json",  # è¾“å‡ºJSONè·¯å¾„ï¼ˆåŒæ­¥æ›´æ–°ï¼‰
    class_mapping: dict = {0: "éåŠ æ²¹ç«™åœºæ™¯", 1: "åŠ æ²¹ç«™åœºæ™¯"}  # å¯æŒ‰éœ€ä¿®æ”¹åˆ†ç±»ç›®æ ‡
) -> str:
    """
    DeepSeeké£æ ¼å›¾åƒè¯†åˆ«æµç¨‹ï¼šè¯»å–â†’é¢„å¤„ç†â†’æ¨ç†â†’JSONè¾“å‡º
    :return: ç»“æ„åŒ–JSONå­—ç¬¦ä¸²ï¼ˆä¾¿äºæŸ¥çœ‹å’ŒäºŒæ¬¡è°ƒç”¨ï¼‰
    """
    # 1. ç¯å¢ƒåˆå§‹åŒ–ï¼ˆé€‚é…CPU/GPUï¼Œå‚è€ƒæ–‡æ¡£è®¾å¤‡é…ç½®é€»è¾‘ï¼‰
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ”§ DeepSeekæ¨ç†ç¯å¢ƒï¼š{device}")

    # 2. å›¾åƒé¢„å¤„ç†ï¼ˆæ ‡å‡†åŒ–+å°ºå¯¸ç»Ÿä¸€ï¼Œé¿å…æ¨ç†å¹²æ‰°ï¼‰
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Resize((224, 224)),  # é€‚é…æ¨¡å‹è¾“å…¥å°ºå¯¸
        transforms.Normalize(mean=[127.5], std=[127.5])  # ç°åº¦å›¾å½’ä¸€åŒ–ï¼ˆåŒ¹é…è®­ç»ƒåˆ†å¸ƒï¼‰
    ])
    try:
        img = load_image_safely(img_path)
        img_tensor = transform(img).unsqueeze(0).to(device)  # å¢åŠ æ‰¹æ¬¡ç»´åº¦ï¼ˆæ¨¡å‹è¦æ±‚ï¼‰
        print(f"ğŸ“¥ æˆåŠŸåŠ è½½å›¾åƒï¼š{os.path.basename(img_path)} | åŸå§‹å°ºå¯¸ï¼š{img.shape[0]}Ã—{img.shape[1]}")
    except Exception as e:
        print(f"âŒ å›¾åƒé¢„å¤„ç†å¤±è´¥ï¼š{str(e)}")
        return json.dumps({"è¯†åˆ«çŠ¶æ€": "å¤±è´¥", "é”™è¯¯ä¿¡æ¯": str(e)}, ensure_ascii=False, indent=4)

    # 3. æ¨¡å‹åˆå§‹åŒ–ï¼ˆè½»é‡çº§ä¼˜å…ˆï¼Œé€‚é…CPUæ¨ç†ï¼‰
    model = DeepSeekLightModel(num_classes=len(class_mapping)).to(device)
    # åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ˆæ¨¡æ‹Ÿéƒ¨ç½²åœºæ™¯ï¼Œæ— æƒé‡åˆ™ç”¨éšæœºåˆå§‹åŒ–æ¼”ç¤ºï¼‰
    try:
        model.load_state_dict(torch.load("deepseek_light_image.pth", map_location=device))
        print("âœ… åŠ è½½DeepSeeké£æ ¼é¢„è®­ç»ƒæ¨¡å‹æˆåŠŸ")
    except FileNotFoundError:
        print("âš ï¸ æœªæ‰¾åˆ°é¢„è®­ç»ƒæƒé‡ï¼Œä½¿ç”¨é»˜è®¤åˆå§‹åŒ–æ¨¡å‹ï¼ˆä»…ä½œåŠŸèƒ½éªŒè¯ï¼Œå®é™…éœ€è®­ç»ƒåä½¿ç”¨ï¼‰")

    # 4. é«˜æ•ˆæ¨ç†ï¼ˆç¦ç”¨æ¢¯åº¦ï¼Œé™ä½CPUèµ„æºæ¶ˆè€—ï¼‰
    model.eval()
    start_time = time.time()
    with torch.no_grad():
        logits = model(img_tensor)
        pred_probs = F.softmax(logits, dim=1).cpu().numpy()[0]  # æ¦‚ç‡å½’ä¸€åŒ–ï¼ˆ0~1ï¼‰
        pred_class_idx = int(torch.argmax(logits, dim=1).item())  # é¢„æµ‹ç±»åˆ«ç´¢å¼•
        infer_time = time.time() - start_time  # ç»Ÿè®¡æ¨ç†è€—æ—¶

    # 5. ç»“æœç»“æ„åŒ–ï¼ˆDeepSeeké£æ ¼ï¼šå­—æ®µæ¸…æ™°ï¼ŒåŒ…å«å…³é”®å…ƒæ•°æ®ï¼‰
    file_basic_info = {
        "æ–‡ä»¶å": os.path.basename(img_path),
        "æ–‡ä»¶ç»å¯¹è·¯å¾„": img_path,
        "æ–‡ä»¶å¤§å°(KB)": round(os.path.getsize(img_path) / 1024, 2),  # è½¬ä¸ºKBä¾¿äºç†è§£
        "å›¾åƒåŸå§‹å°ºå¯¸(é«˜Ã—å®½)": f"{img.shape[0]}Ã—{img.shape[1]}",
        "å›¾åƒè¾“å…¥æ¨¡å‹å°ºå¯¸": "224Ã—224ï¼ˆç°åº¦å›¾ï¼‰"
    }
    recognition_detail = {
        "é¢„æµ‹ç±»åˆ«": class_mapping[pred_class_idx],
        "å„ç±»åˆ«é¢„æµ‹æ¦‚ç‡": {class_mapping[i]: round(float(pred_probs[i]), 4) for i in range(len(class_mapping))},
        "å•å›¾æ¨ç†æ—¶é—´(ç§’)": round(infer_time, 4),
        "ä½¿ç”¨æ¨¡å‹æ¶æ„": "DeepSeeké£æ ¼è½»é‡çº§CNNï¼ˆæ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼‰",
        "æ¨ç†è®¾å¤‡": str(device),
        "æ¨¡å‹å‚æ•°é‡(çº¦)": "0.05Mï¼ˆ5ä¸‡å‚æ•°ï¼Œè½»é‡åŒ–è®¾è®¡ï¼‰"
    }
    final_result = {
        "è¯†åˆ«çŠ¶æ€": "æˆåŠŸ",
        "æ–‡ä»¶åŸºæœ¬ä¿¡æ¯": file_basic_info,
        "è¯†åˆ«ç»“æœè¯¦æƒ…": recognition_detail,
        "ç»“æœç”Ÿæˆæ—¶é—´": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
    }

    # 6. ä¿å­˜JSONï¼ˆç»“æ„åŒ–å­˜å‚¨ï¼Œä¾¿äºåç»­åˆ†ææˆ–è°ƒç”¨ï¼‰
    try:
        with open(output_json, "w", encoding="utf-8") as f:
            json.dump(final_result, f, ensure_ascii=False, indent=4)
        print(f"\nğŸ‰ è¯†åˆ«å®Œæˆï¼JSONç»“æœå·²ä¿å­˜è‡³ï¼š{os.path.abspath(output_json)}")
    except Exception as save_err:
        print(f"âš ï¸ JSONä¿å­˜å¤±è´¥ï¼š{str(save_err)}ï¼Œä»…è¿”å›æ§åˆ¶å°ç»“æœ")

    # è¿”å›JSONå­—ç¬¦ä¸²ï¼ˆä¾¿äºæ§åˆ¶å°é¢„è§ˆå’Œåç»­ç¨‹åºè°ƒç”¨ï¼‰
    return json.dumps(final_result, ensure_ascii=False, indent=4)

# ---------------------- 4. æ‰§è¡Œå…¥å£ï¼ˆDeepSeekï¼šç®€æ´è°ƒç”¨ï¼Œé™ä½ä½¿ç”¨æˆæœ¬ï¼‰ ----------------------
if __name__ == "__main__":
    # ä¾èµ–å®‰è£…æç¤ºï¼ˆé¦–æ¬¡è¿è¡Œéœ€æ‰§è¡Œï¼‰
    print("âš ï¸ é¦–æ¬¡è¿è¡Œè¯·å…ˆå®‰è£…ä¾èµ–ï¼špip install torch torchvision opencv-python numpy pillow")
    # æ‰§è¡Œè¯†åˆ«æµç¨‹ï¼ˆè‡ªåŠ¨å¤„ç†ç›®æ ‡å›¾åƒï¼‰
    result_json = deepseek_image_recognition()
    # æ§åˆ¶å°æ‰“å°ç»“æœé¢„è§ˆ
    print("\nğŸ“Š å›¾åƒè¯†åˆ«ç»“æœï¼ˆJSONæ ¼å¼ï¼‰ï¼š")
    print(result_json)