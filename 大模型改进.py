import os
import cv2
import json
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms
import time

# ---------------------- 1. åŸºç¡€å·¥å…·æ¨¡å—ï¼ˆä¿ç•™åŸé€»è¾‘ï¼Œé€‚é…æ–‡æ¡£å›¾åƒè¯»å–ï¼‰ ----------------------
def validate_file_path(file_path: str) -> None:
    """éªŒè¯æ–‡ä»¶è·¯å¾„æœ‰æ•ˆæ€§ï¼ˆç¡®ä¿æ˜¯å›¾åƒæ ¼å¼ï¼‰"""
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼š{file_path}\nè¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®æˆ–æ–‡ä»¶æ˜¯å¦è¢«åˆ é™¤")
    valid_ext = ('.png', '.jpg', '.jpeg', '.bmp')  # é€‚é…å¸¸è§æ–‡æ¡£æ‰«æå›¾åƒæ ¼å¼
    if not file_path.lower().endswith(valid_ext):
        raise ValueError(f"æ–‡ä»¶æ ¼å¼ä¸æ”¯æŒï¼š{file_path}\nä»…æ”¯æŒ{valid_ext}æ ¼å¼çš„å›¾åƒæ–‡ä»¶")

def load_image_safely(file_path: str) -> np.ndarray:
    """å®‰å…¨åŠ è½½æ–‡æ¡£å›¾åƒï¼ˆPIL+OpenCVåŒå…¼å®¹ï¼Œè§£å†³æ‰«æä»¶/ç‰¹æ®Šç¼–ç é—®é¢˜ï¼‰"""
    validate_file_path(file_path)
    # ä¼˜å…ˆç”¨PILè¯»å–ï¼ˆé€‚é…æ–‡æ¡£æ‰«æä»¶ï¼Œå¦‚è¥ä¸šæ‰§ç…§ã€æŠ¥è¡¨æ‰«æå›¾ï¼‰
    try:
        from PIL import Image
        # è½¬ä¸ºç°åº¦å›¾ï¼ˆæ–‡æ¡£å›¾åƒå¤šä¸ºé»‘ç™½/ç°åº¦ï¼Œé™ä½æ¨¡å‹å¤æ‚åº¦ï¼‰
        img_pil = Image.open(file_path).convert('L')
        img = np.array(img_pil)
        return img
    except ImportError:
        # OpenCVå…œåº•è¯»å–ï¼ˆå¤šæ¨¡å¼é€‚é…ï¼‰
        read_modes = [cv2.IMREAD_GRAYSCALE, cv2.IMREAD_COLOR, cv2.IMREAD_UNCHANGED]
        for mode in read_modes:
            img = cv2.imread(file_path, mode)
            if img is not None:
                if len(img.shape) == 3:
                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                return img
    except Exception as pil_err:
        # PILå¤±è´¥æ—¶ï¼ŒOpenCVäºŒæ¬¡å°è¯•
        read_modes = [cv2.IMREAD_GRAYSCALE, cv2.IMREAD_COLOR, cv2.IMREAD_UNCHANGED]
        for mode in read_modes:
            img = cv2.imread(file_path, mode)
            if img is not None:
                if len(img.shape) == 3:
                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                return img
    # æ‰€æœ‰æ–¹å¼å¤±è´¥ï¼ŒæŠ›å‡ºä¸šåŠ¡ç›¸å…³é”™è¯¯æç¤º
    raise Exception(
        f"æ–‡æ¡£å›¾åƒåŠ è½½å¤±è´¥ï¼š{file_path}\n"
        f"å¯èƒ½åŸå› ï¼š1.æ–‡ä»¶æŸå 2.éæ ‡å‡†å›¾åƒæ ¼å¼ 3.æƒé™ä¸è¶³ 4.æœªå®‰è£…PILåº“ï¼ˆæ‰§è¡Œpip install pillowä¿®å¤ï¼‰"
    )

# ---------------------- 2. DeepSeeké£æ ¼æ–‡æ¡£ç±»å‹åˆ†ç±»æ¨¡å‹ï¼ˆæ–°å¢4ç±»åˆ†ç±»é€»è¾‘ï¼‰ ----------------------
class DeepSeekDocTypeModel(nn.Module):
    """è½»é‡çº§æ–‡æ¡£ç±»å‹åˆ†ç±»æ¨¡å‹ï¼ˆé€‚é…4ç±»è´·æ¬¾å®¢æˆ·èµ„æ–™ï¼šå‘ç¥¨/èµ„äº§è´Ÿå€ºè¡¨/åˆ©æ¶¦è¡¨/è¥ä¸šæ‰§ç…§ï¼‰"""
    def __init__(self, num_classes: int = 4):  # æ”¹ä¸º4ç±»åˆ†ç±»
        super().__init__()
        # ç‰¹å¾æå–å±‚ï¼šæ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼ˆä¿ç•™è½»é‡åŒ–ï¼Œé€‚é…CPUæ¨ç†ï¼Œå‚è€ƒæ–‡æ¡£Mobilenetv3_smallï¼‰
        self.features = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, padding=1),  # è¾“å…¥ï¼š1é€šé“ï¼ˆç°åº¦æ–‡æ¡£å›¾åƒï¼‰
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, kernel_size=3, padding=1, groups=32),  # æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼ˆé™å‚ï¼‰
            nn.Conv2d(64, 64, kernel_size=1),  # ç‚¹å·ç§¯è°ƒæ•´é€šé“
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(64, 128, kernel_size=3, padding=1, groups=64),  # æ–°å¢ä¸€å±‚æå‡åˆ†ç±»èƒ½åŠ›
            nn.Conv2d(128, 128, kernel_size=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )
        # åˆ†ç±»å±‚ï¼šé€‚é…4ç±»è¾“å‡º
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, num_classes)  # è¾“å‡º4ç±»æ¦‚ç‡
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.features(x)
        x = self.classifier(x)
        return x

# ---------------------- 3. æ ¸å¿ƒæµç¨‹ï¼ˆæ–°å¢4ç±»æ–‡æ¡£ç±»å‹è¯†åˆ«ï¼Œä¿ç•™åŸç»“æ„åŒ–è¾“å‡ºï¼‰ ----------------------
def deepseek_doc_type_recognition(
    img_path: str = r"C:\Users\thy\Desktop\å›¾åƒ1.png",  # ç›®æ ‡æ–‡æ¡£å›¾åƒè·¯å¾„
    output_json: str = r"C:\Users\thy\Desktop\è´·æ¬¾å®¢æˆ·æ–‡æ¡£è¯†åˆ«ç»“æœ.json",  # ä¸šåŠ¡åŒ–è¾“å‡ºè·¯å¾„
    doc_type_mapping: dict = {  # æ–°å¢ï¼šè´·æ¬¾å®¢æˆ·4ç±»æ–‡æ¡£æ˜ å°„ï¼ˆæ ¸å¿ƒé™åˆ¶ï¼‰
        0: "å‘ç¥¨",
        1: "èµ„äº§è´Ÿå€ºè¡¨",
        2: "åˆ©æ¶¦è¡¨",
        3: "è¥ä¸šæ‰§ç…§"
    }
) -> str:
    """
    DeepSeeké£æ ¼è´·æ¬¾å®¢æˆ·æ–‡æ¡£ç±»å‹è¯†åˆ«ï¼šè¯»å–å›¾åƒâ†’åˆ¤åˆ«ç±»å‹â†’ç”Ÿæˆç»“æ„åŒ–JSON
    ä»…æ”¯æŒ4ç±»æ–‡æ¡£ï¼šå‘ç¥¨ã€èµ„äº§è´Ÿå€ºè¡¨ã€åˆ©æ¶¦è¡¨ã€è¥ä¸šæ‰§ç…§
    """
    # 1. ç¯å¢ƒåˆå§‹åŒ–ï¼ˆé€‚é…CPU/GPUï¼Œç¡®ä¿ä¸šåŠ¡éƒ¨ç½²å…¼å®¹æ€§ï¼‰
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ”§ DeepSeekæ¨ç†ç¯å¢ƒï¼š{device} | æ”¯æŒæ–‡æ¡£ç±»å‹ï¼š{list(doc_type_mapping.values())}")

    # 2. æ–‡æ¡£å›¾åƒé¢„å¤„ç†ï¼ˆé€‚é…æ–‡æ¡£ç‰¹å¾ï¼šå¦‚æ–‡å­—å¯†é›†åŒºåŸŸã€è¡¨æ ¼ç»“æ„ï¼‰
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Resize((224, 224)),  # ç»Ÿä¸€è¾“å…¥å°ºå¯¸ï¼ˆé€‚é…æ¨¡å‹ï¼‰
        transforms.Normalize(mean=[127.5], std=[127.5])  # ç°åº¦å›¾å½’ä¸€åŒ–ï¼ˆç¨³å®šæ¨ç†ï¼‰
    ])
    try:
        img = load_image_safely(img_path)
        img_tensor = transform(img).unsqueeze(0).to(device)  # å¢åŠ æ‰¹æ¬¡ç»´åº¦
        print(f"ğŸ“¥ æˆåŠŸåŠ è½½æ–‡æ¡£å›¾åƒï¼š{os.path.basename(img_path)} | åŸå§‹å°ºå¯¸ï¼š{img.shape[0]}Ã—{img.shape[1]}")
    except Exception as e:
        print(f"âŒ æ–‡æ¡£é¢„å¤„ç†å¤±è´¥ï¼š{str(e)}")
        return json.dumps({
            "è¯†åˆ«çŠ¶æ€": "å¤±è´¥",
            "é”™è¯¯ä¿¡æ¯": str(e),
            "æ”¯æŒæ–‡æ¡£ç±»å‹": list(doc_type_mapping.values())
        }, ensure_ascii=False, indent=4)

    # 3. æ¨¡å‹åˆå§‹åŒ–ï¼ˆ4ç±»æ–‡æ¡£åˆ†ç±»ä¸“ç”¨ï¼‰
    model = DeepSeekDocTypeModel(num_classes=len(doc_type_mapping)).to(device)
    # åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ˆæ¨¡æ‹Ÿä¸šåŠ¡éƒ¨ç½²ï¼šå®é™…éœ€ç”¨4ç±»æ–‡æ¡£æ•°æ®é›†è®­ç»ƒåä¿å­˜ï¼‰
    try:
        model.load_state_dict(torch.load("deepseek_doc_type_model.pth", map_location=device))
        print("âœ… åŠ è½½DeepSeeké£æ ¼æ–‡æ¡£ç±»å‹é¢„è®­ç»ƒæ¨¡å‹æˆåŠŸ")
    except FileNotFoundError:
        print("âš ï¸ æœªæ‰¾åˆ°é¢„è®­ç»ƒæƒé‡ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–æ¨¡å‹ï¼ˆä»…ä½œåŠŸèƒ½æ¼”ç¤ºï¼Œå®é™…éœ€è®­ç»ƒåä½¿ç”¨ï¼‰")

    # 4. æ–‡æ¡£ç±»å‹æ¨ç†ï¼ˆé«˜æ•ˆè®¡ç®—ï¼Œé€‚é…æ‰¹é‡å®¡æ ¸åœºæ™¯ï¼‰
    model.eval()
    start_time = time.time()
    with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦ï¼Œé™ä½CPUæ¶ˆè€—
        logits = model(img_tensor)
        pred_probs = F.softmax(logits, dim=1).cpu().numpy()[0]  # 4ç±»æ¦‚ç‡å½’ä¸€åŒ–
        pred_type_idx = int(torch.argmax(logits, dim=1).item())  # é¢„æµ‹ç±»å‹ç´¢å¼•
        pred_doc_type = doc_type_mapping[pred_type_idx]  # æ˜ å°„ä¸ºå…·ä½“æ–‡æ¡£ç±»å‹
        infer_time = time.time() - start_time

    # 5. ä¸šåŠ¡åŒ–ç»“æ„åŒ–è¾“å‡ºï¼ˆæ–°å¢æ–‡æ¡£ç±»å‹æ ¸å¿ƒå­—æ®µï¼Œä¾¿äºè´·æ¬¾å®¡æ ¸å¯¹æ¥ï¼‰
    file_basic_info = {
        "æ–‡æ¡£æ–‡ä»¶å": os.path.basename(img_path),
        "æ–‡æ¡£ç»å¯¹è·¯å¾„": img_path,
        "æ–‡ä»¶å¤§å°(KB)": round(os.path.getsize(img_path) / 1024, 2),
        "å›¾åƒåŸå§‹å°ºå¯¸(é«˜Ã—å®½)": f"{img.shape[0]}Ã—{img.shape[1]}",
        "é¢„å¤„ç†åå°ºå¯¸": "224Ã—224ï¼ˆç°åº¦å›¾ï¼‰"
    }
    doc_recognition_detail = {
        "è¯†åˆ«æ–‡æ¡£ç±»å‹": pred_doc_type,  # æ ¸å¿ƒç»“æœï¼š4ç±»ä¸­çš„ä¸€ç±»
        "å„ç±»æ–‡æ¡£ç±»å‹æ¦‚ç‡": {doc_type_mapping[i]: round(float(pred_probs[i]), 4) for i in range(len(doc_type_mapping))},
        "å•æ–‡æ¡£æ¨ç†æ—¶é—´(ç§’)": round(infer_time, 4),
        "ä½¿ç”¨æ¨¡å‹": "DeepSeeké£æ ¼è½»é‡çº§æ–‡æ¡£åˆ†ç±»CNNï¼ˆæ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼‰",
        "æ¨ç†è®¾å¤‡": str(device),
        "æ”¯æŒæ–‡æ¡£ç±»å‹èŒƒå›´": list(doc_type_mapping.values()),
        "æ¨¡å‹å‚æ•°é‡(çº¦)": "0.12Mï¼ˆ12ä¸‡å‚æ•°ï¼Œè½»é‡åŒ–é€‚é…ä¸šåŠ¡éƒ¨ç½²ï¼‰"
    }
    final_result = {
        "è¯†åˆ«çŠ¶æ€": "æˆåŠŸ",
        "è´·æ¬¾å®¢æˆ·æ–‡æ¡£ä¿¡æ¯": file_basic_info,
        "æ–‡æ¡£ç±»å‹è¯†åˆ«ç»“æœ": doc_recognition_detail,
        "ç»“æœç”Ÿæˆæ—¶é—´": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()),
        "ä¸šåŠ¡è¯´æ˜": "ä»…ç”¨äºè´·æ¬¾å®¢æˆ·æä¾›çš„4ç±»æ–‡æ¡£ç±»å‹åˆ¤åˆ«ï¼Œéæ­¤èŒƒå›´æ–‡æ¡£å°†æ ‡è®°ä¸ºè¯†åˆ«å¤±è´¥"
    }

    # 6. ä¿å­˜ä¸šåŠ¡åŒ–JSONï¼ˆä¾¿äºå¯¹æ¥è´·æ¬¾å®¡æ ¸ç³»ç»Ÿï¼‰
    try:
        with open(output_json, "w", encoding="utf-8") as f:
            json.dump(final_result, f, ensure_ascii=False, indent=4)
        print(f"\nğŸ‰ æ–‡æ¡£ç±»å‹è¯†åˆ«å®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³ï¼š{os.path.abspath(output_json)}")
    except Exception as save_err:
        print(f"âš ï¸ JSONä¿å­˜å¤±è´¥ï¼š{str(save_err)}ï¼Œä»…è¿”å›æ§åˆ¶å°ç»“æœ")

    return json.dumps(final_result, ensure_ascii=False, indent=4)

# ---------------------- 4. ä¸šåŠ¡åŒ–æ‰§è¡Œå…¥å£ï¼ˆé€‚é…è´·æ¬¾å®¢æˆ·èµ„æ–™å®¡æ ¸åœºæ™¯ï¼‰ ----------------------
if __name__ == "__main__":
    # ä¾èµ–å®‰è£…æç¤ºï¼ˆé¦–æ¬¡è¿è¡Œï¼‰
    print("âš ï¸ é¦–æ¬¡è¿è¡Œè¯·å®‰è£…ä¾èµ–ï¼špip install torch torchvision opencv-python numpy pillow")
    # æ‰§è¡Œæ–‡æ¡£ç±»å‹è¯†åˆ«ï¼ˆé»˜è®¤å¤„ç†ç›®æ ‡å›¾åƒï¼Œå¯æ‰¹é‡å¾ªç¯è°ƒç”¨ï¼‰
    result_json = deepseek_doc_type_recognition(
        img_path=r"C:\Users\thy\Desktop\å›¾åƒ1.png",  # å¯æ›¿æ¢ä¸ºå®¢æˆ·æä¾›çš„æ–‡æ¡£å›¾åƒè·¯å¾„
        output_json=r"C:\Users\thy\Desktop\è´·æ¬¾å®¢æˆ·æ–‡æ¡£è¯†åˆ«ç»“æœ.json"
    )
    # æ§åˆ¶å°æ‰“å°ä¸šåŠ¡åŒ–ç»“æœ
    print("\nğŸ“Š è´·æ¬¾å®¢æˆ·æ–‡æ¡£ç±»å‹è¯†åˆ«ç»“æœï¼ˆJSONæ ¼å¼ï¼‰ï¼š")
    print(result_json)